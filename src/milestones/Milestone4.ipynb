{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dane Jordan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 8 Data Competition Milestones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import urllib.request\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "x = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/train_features'))\n",
    "test_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/test_features'))\n",
    "y = np.array(pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/train_labels')))\n",
    "y = y.astype(float)\n",
    "\n",
    "# image transformations not used for this milestone\n",
    "# color_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/color_features'))\n",
    "# compress_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/compress_features'))\n",
    "# crop_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/crop_features'))\n",
    "# crop_to_corner_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/crop_to_corner_features'))\n",
    "# homography_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/homography_features'))\n",
    "# mirror_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/mirror_features'))\n",
    "# rotate30_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/rotate30_features'))\n",
    "# scale_set = pickle.load(urllib.request.urlopen('https://s3.amazonaws.com/stat558drjordankaggle/scale_features'))\n",
    "\n",
    "# subset the data if looking to analyze a smaller set of classes\n",
    "classes = np.unique(y)\n",
    "index = np.ravel(np.nonzero(np.in1d(y, classes)))\n",
    "x_subset = x[index]\n",
    "y_subset = y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data_equal(x, y, test_set, train_size=0.75):\n",
    "    # split into train and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_size, random_state=0, stratify=y)\n",
    "    \n",
    "    # center and standardize x values\n",
    "    x_scaler = StandardScaler().fit(x_train)\n",
    "    x_train = x_scaler.transform(x_train)\n",
    "    x_test = x_scaler.transform(x_test)\n",
    "    test_set = x_scaler.transform(test_set)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, test_set\n",
    "\n",
    "\n",
    "def decomp_PCA(train, test, test_set, explained_var_threshold=0.95):\n",
    "    pca = PCA().fit(train)\n",
    "\n",
    "    pca_explained_var_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "    pca_explained_var = []\n",
    "    num_component_vectors = 0\n",
    "\n",
    "    while np.sum(pca_explained_var) < explained_var_threshold:\n",
    "        pca_explained_var.append(pca_explained_var_ratio[num_component_vectors])\n",
    "        num_component_vectors += 1\n",
    "    #print('# Component Vectors: %d    Explained Var: %f' % (num_component_vectors, np.sum(pca_explained_var)))\n",
    "\n",
    "    pca = PCA(n_components=num_component_vectors).fit(train)\n",
    "    x_train = pca.transform(train)\n",
    "    x_test = pca.transform(test)\n",
    "    test_set = pca.transform(test_set)\n",
    "    \n",
    "    return x_train, x_test, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test, test_set = split_data_equal(x=x_subset, y=y_subset, test_set=test_set, train_size=0.75)\n",
    "n = x_train.shape[0]\n",
    "d = x_train.shape[1]\n",
    "\n",
    "# run PCA to reduce dimensionality and speed up processing time\n",
    "x_train, x_test, test_set = decomp_PCA(train=x_train, test=x_test, test_set=test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare the performance of SVMs for diﬀerent types of kernels, tuning the kernel parameters using cross-validation. You may train the SVMs for multi-class classiﬁcation in any fashion you wish (one-vs-one, one-vs-rest, multiclass). You may also use scikit-learn’s built-in functions to perform cross-validation over all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rbf kernel ovo\n",
    "rbfSVC = SVC()\n",
    "parameters = {'C':[10**i for i in range(-2, 2)]}\n",
    "rbfCV = GridSearchCV(rbfSVC, parameters, n_jobs=-1)\n",
    "rbfCV_fitted = rbfCV.fit(x_train, y_train)\n",
    "\n",
    "# polynomial (order 2) kernel ovo\n",
    "poly2SVC = SVC(kernel='poly', degree=2)\n",
    "parameters = {'C':[10**i for i in range(-2, 2)]}\n",
    "poly2CV = GridSearchCV(poly2SVC, parameters, n_jobs=-1)\n",
    "poly2CV_fitted = poly2CV.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf Accuracy: 57.870370%\n",
      "poly2 Accuracy: 67.500000%\n"
     ]
    }
   ],
   "source": [
    "# accuracy predictions\n",
    "y_predict_rbf = rbfCV_fitted.predict(x_test)\n",
    "y_predict_poly2 = poly2CV_fitted.predict(x_test)\n",
    "print('rbf Accuracy: %f%%' % (np.mean(y_predict_rbf == y_test)*100))\n",
    "print('poly2 Accuracy: %f%%' % (np.mean(y_predict_poly2 == y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Experiment with several ensembles of classiﬁers, using any technique you wish. You may consider bagging (ensembles of classiﬁers learnt from random subsamples of examples), ensemble of classiﬁers learnt from random subsets of features, ensembles of classiﬁers with diﬀerent kernels, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use rbf kernel with bagging classifier\n",
    "rbf_bag = BaggingClassifier(base_estimator=rbfCV, n_jobs=-1).fit(x_train, y_train)\n",
    "\n",
    "# use polynomial (order 2) kernel with bagging classifier\n",
    "poly2_bag = BaggingClassifier(base_estimator=poly2CV, n_jobs=-1).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf bagging Accuracy: 54.444444%\n",
      "poly2 bagging Accuracy: 65.555556%\n"
     ]
    }
   ],
   "source": [
    "# accuracy prediction\n",
    "y_predict_rbf_bag = rbf_bag.predict(x_test)\n",
    "y_predict_poly2_bag = poly2_bag.predict(x_test)\n",
    "print('rbf bagging Accuracy: %f%%' % (np.mean(y_predict_rbf_bag == y_test)*100))\n",
    "print('poly2 bagging Accuracy: %f%%' % (np.mean(y_predict_poly2_bag == y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
